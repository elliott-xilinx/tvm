{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tvm\n",
    "import nnvm\n",
    "import topi\n",
    "\n",
    "import nnvm.symbol as sb\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "EXAMPLE = 1\n",
    "target, target_host = 'llvm', 'llvm'\n",
    "ctx = tvm.cpu(0)\n",
    "\n",
    "os.environ['XDNN_VERBOSE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libxilinxopencl.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import xdnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkfile None\n",
      "memory 5\n",
      "dsp 56\n",
      "generatefile temp_fpga_code.cmds\n",
      "fromtensorflow False\n",
      "weights weights\n",
      "pngfile graph.png\n",
      "verbose True\n",
      "Namespace(anew=None, approximate=False, banditpre=None, barrier=False, bridges=None, bytesperpixels=2, concatstrategy=None, conv_1x1_s2=False, cpulayermustgo=False, ddr=256, dedicateddsp=None, dsp=56, fc=False, finalnode=None, forceweights=None, fromtensorflow=False, frontendonly=False, generatefile='temp_fpga_code.cmds', godreplication=None, godtiling=None, initialnode=None, lasttensorbyname=None, leavescalealone=False, loadpickle=None, manasadebugmode=False, manualbatch=False, manualdeconv=False, memory=5, mixmemorystrategy=False, networkfile='None', nodynamicscaling=False, noreplication=False, notcaffeanew=False, parallelism=False, parallelismgraphalgorithm='tfs', parallelismstrategy=None, parallelread=None, pipelineconvmaxpool=False, placeholdershape=None, pngfile='graph.png', poolingaround=False, quant_cfgfile=None, rankdir='BT', savepickle=None, schedulefile=None, splitonly=False, strategy='all', textmode=False, usedeephi=False, verbose=True, versionjson=None, weights='weights')\n",
      "Network: None\n",
      "GenerateCode: temp_fpga_code.cmds\n",
      "Weights: weights\n",
      "PngFile: graph.png\n",
      "ConcatStrategy: None\n",
      "Strategy: all\n",
      "ScheduleFile: None\n",
      "DDR: 256\n",
      "DSP: 56\n",
      "DSP V2\n",
      "Verbose: True\n",
      "FromTF: False\n",
      "Memory: 5\n",
      "**************************************************\n",
      "* HARDWARE\n",
      "**************************************************\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DDR INPUT  NONE\n",
      "==========\n",
      "DDR OUTPUT NONE\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      2\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         0\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "[{'op': 'null', 'name': 'x', 'inputs': []}, {'op': 'max_pool2d', 'name': 'max_pool2d0', 'attrs': {'pool_size': '[2, 2]', 'strides': '[2, 2]'}, 'inputs': [[0, 0, 0]]}]\n",
      "<class 'nnvm.top.attr_dict.AttrDict'>\n",
      "max_pool2d max_pool2d0 {'padding': '[0,0]', 'pool_size': '[2,2]', 'ceil_mode': '0', 'strides': '[2,2]', 'layout': 'NCHW'} ['input0'] [[1, 1, 4, 4], [1, 1, 2, 2]] NCHW {}\n",
      "Start transformation to xfDNN IR of:\t input0\n",
      "Node shape:\t SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Start transformation to xfDNN IR of:\t max_pool2d0\n",
      "Node shape:\t SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Creating blob:\t input0\n",
      "Creating blob:\t max_pool2d0\n",
      "\n",
      "Building graph edges\n",
      "Name:  input0 \tLayer type:  ['Placeholder']\n",
      "Name:  max_pool2d0 \tLayer type:  ['Pooling']\n",
      "Writing graph visualization to from_nnvm_graph.png\n",
      "**************************************************\n",
      "* XFDNN GRAPH SCHEDULE\n",
      "**************************************************\n",
      "inferred\n",
      "0 0 name input0 type Placeholder fpga False bottoms [] [Extras None]-  Past [] -> Future []\n",
      "1 1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "**************************************************\n",
      "* INITIALIZE HW ABSTRACTION\n",
      "**************************************************\n",
      "DSP: 56\n",
      "DSP V2\n",
      "Memory: 5\n",
      "DDR: 256\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DDR INPUT  NONE\n",
      "==========\n",
      "DDR OUTPUT NONE\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      2\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         0\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "**************************************************\n",
      "* CONVERTING GRAPH TO SCHEDULE\n",
      "**************************************************\n",
      "('## Schedule', 2, 2)\n",
      "(0, \"['input0']\")\n",
      "(1, \"['max_pool2d0']\")\n",
      "(0, 'input0')\n",
      "(1, 'max_pool2d0')\n",
      "**************************************************\n",
      "* Graph Manipulations\n",
      "**************************************************\n",
      "P.kernel_sizes [2, 2]\n",
      "<class 'argparse.Namespace'>\n",
      "{'generatefile': 'temp_fpga_code.cmds', 'pngfile': 'graph.png', 'concatstrategy': None, 'quant_cfgfile': None, 'anew': None, 'strategy': 'all', 'versionjson': None, 'lasttensorbyname': None, 'schedulefile': None, 'usedeephi': False, 'savepickle': None, 'loadpickle': None, 'dsp': 56, 'bytesperpixels': 2, 'verbose': True, 'pipelineconvmaxpool': False, 'parallelism': False, 'parallelismgraphalgorithm': 'tfs', 'parallelismstrategy': None, 'parallelread': None, 'noreplication': False, 'frontendonly': False, 'barrier': False, 'approximate': False, 'leavescalealone': False, 'memory': 5, 'ddr': 256, 'manasadebugmode': False, 'fromtensorflow': False, 'cpulayermustgo': False, 'conv_1x1_s2': False, 'poolingaround': False, 'nodynamicscaling': False, 'dedicateddsp': None, 'bridges': None, 'banditpre': None, 'godreplication': None, 'godtiling': None, 'forceweights': None, 'notcaffeanew': False, 'mixmemorystrategy': False, 'splitonly': False, 'rankdir': 'BT', 'networkfile': 'None', 'placeholdershape': None, 'weights': 'weights', 'textmode': False, 'finalnode': None, 'initialnode': None, 'manualbatch': False, 'fc': False, 'manualdeconv': False}\n",
      "**************************************************\n",
      "* Graph weight manipulation\n",
      "**************************************************\n",
      "node_ReLU_collapse_rm\n",
      "Writing graph visualization to ./original_beforememory.png\n",
      "inferred\n",
      "0 0 name input0 type Placeholder fpga False bottoms [] [Extras None]-  Past [] -> Future []\n",
      "1 1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "Writing graph visualization to graph.png\n",
      "Optimizing 1 schedules\n",
      "Schedule inferred\n",
      "inferred\n",
      "0 0 name input0 type Placeholder fpga False bottoms [] [Extras None]-  Past [] -> Future []\n",
      "1 1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "**************************************************\n",
      "* COMPUTING MEMORY REQUIREMENTS\n",
      "**************************************************\n",
      "standard_schedule_min_memory 3 <class 'dagtools_type.Schedule'>\n",
      "Schedule for initialization {0: ['input0'], 1: ['max_pool2d0']}\n",
      "Schedule for initialization {'input0': 0, 'max_pool2d0': 1}\n",
      "Schedule for initialization nodes matches  2\n",
      "initializing  input0_blob\n",
      "input0_blob [LayerParameter=ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None), fillcolor=\"#E0E0E0\", shape=octagon, style=filled];\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 1024 UUUUU\n",
      "1024 SizeType(batches=1, channels=1, height=4, width=4)\n",
      "IO @@@ input0_blob MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "initializing  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "initialized blob input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None) ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[])\n",
      "initializing  max_pool2d0_blob\n",
      "max_pool2d0_blob [LayerParameter=ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}), fillcolor=\"#E0E0E0\", shape=octagon, style=filled];\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 512 UUUUU\n",
      "512 SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IO @@@ max_pool2d0_blob MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "initializing  ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "initialized blob max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0]) ColorForDAG(active=[0], schedule=-1, forward=[], backward=[1], extra=None, hook=[])\n",
      "Schedule for initialization blobs matches  2\n",
      "2 YYYYYYY\n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None) ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[])\n",
      "\t input MemoryRequirements(size=0, input=[], output=[], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t O input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 1024 UUUUU\n",
      "\t output MemoryRequirements(size=0, input=[], output=[1024, [1024]], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t overall MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "initialize layer input0 input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None) ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[])\n",
      "2 YYYYYYY\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=1, forward=[], backward=[0], extra=None, hook=[])\n",
      "\t I input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 1024 UUUUU\n",
      "\t input MemoryRequirements(size=0, input=[1024, [1024]], output=[], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t O max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 512 UUUUU\n",
      "\t output MemoryRequirements(size=0, input=[1024, [1024]], output=[512, [512]], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t overall MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "initialize layer max_pool2d0 max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=1, forward=[], backward=[0], extra=None, hook=[])\n",
      "Initialization Done\n",
      "Is  []\n",
      "step 0 ['input0']\n",
      "step name 0 input0\n",
      "step dagnode 0 input0\n",
      "active layer  input0 ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None) input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "\t\t activated ->  input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "step _ 0 {'input0_blob': BlobInformation(size=0, name='input0_blob', memory=None, dag=ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "INFO ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "memory 0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "step 1 ['max_pool2d0']\n",
      "step name 1 max_pool2d0\n",
      "step dagnode 1 max_pool2d0\n",
      "active layer  max_pool2d0 ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "\t\t activated ->  max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      "step _ 1 {'input0_blob': BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), 'max_pool2d0_blob': BlobInformation(size=0, name='max_pool2d0_blob', memory=None, dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "INFO ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "memory 1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "\t\t ### deactivated ->  input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None) ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[])\n",
      "{0: ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[]), 1: ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      " Nodes 4 \n",
      "  _____ \n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 3 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "Memory Schedule 2\n",
      "__________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[0,512] Z=512 F=[] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "\n",
      "__________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[0,512] Z=512 F=[] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "\n",
      "Minimum Memory __________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[0,512] Z=512 F=[] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      " Nodes 4 \n",
      "  _____ \n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 3 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "MAX  1\n",
      "TOP 5\n",
      "__________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[0,512] Z=512 F=[] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Using Hardware Version [2]\n",
      "**************************************************\n",
      "* ALLOCATING DYNAMIC MEMORY SCHEDULE\n",
      "**************************************************\n",
      "Allocating Memory all\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DDR INPUT  NONE\n",
      "==========\n",
      "DDR OUTPUT NONE\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      2\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         5\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "Trying no-DDR strategies...\n",
      "Reset Memory\n",
      "Trying strategy bysize (NO DDR)\n",
      "Initial memory map One Slice, One Vision\n",
      "DDR: [(0, 268435456)]\n",
      "boundary 1024 strategy bysize\n",
      "Beginning step 0 __________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Remappping None\n",
      "Concat None\n",
      "blob.name in LFnames False\n",
      "blob True ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "\tlayer ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "layer #  ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "layer # True MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "allocate_am 0 1024\n",
      "slice allocate 1024\n",
      "AM allocate 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "AM allocate SpaceAndTime(space=1024, time=6, replication=None)\n",
      "AM allocate before MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bysize\n",
      "allocate MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bysize ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bysize MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) [(0, 5242880)]\n",
      " slot  MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 5241856 END Address 5243904\n",
      "found ref MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "allocated input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4) \n",
      " \t  [(1024, 5242880)]\n",
      "BLOB bysize input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Beginning step 1 __________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[0,512] Z=512 F=[] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Remappping None\n",
      "Concat None\n",
      "blob.name in LFnames True\n",
      "BLOB bysize input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "blob.name in LFnames False\n",
      "blob True ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "\tlayer ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "layer #  ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "layer # True MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "allocate_am 0 512\n",
      "slice allocate 512\n",
      "AM allocate 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "AM allocate SpaceAndTime(space=512, time=7, replication=None)\n",
      "AM allocate before MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bysize\n",
      "allocate MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bysize ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bysize MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) [(1024, 5242880)]\n",
      " slot  MemoryAllocation(start=1024, end=5242880, size=5241856, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 5241344 END Address 5243392\n",
      "found ref MemoryAllocation(start=1024, end=5242880, size=5241856, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "allocated max_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2) \n",
      " \t  [(1536, 5242880)]\n",
      "BLOB bysize max_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "checking for deallocation  [(1536, 5242880)] True input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "FREE SPACE (0, 1024)-MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True)\n",
      "(1536, 5242880)-MemoryAllocation(start=1536, end=5242880, size=5241344, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "\n",
      "freed  1 input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4) \n",
      " \t  [(0, 1024), (1536, 5242880)]\n",
      "checking for deallocation  [(0, 1024), (1536, 5242880)] True max_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "free right join MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True) MemoryAllocation(start=1536, end=5242880, size=5241344, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "free left join MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True) MemoryAllocation(start=1024, end=5242880, size=5241856, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True)\n",
      "FREE SPACE (0, 5242880)-MemoryAllocation(start=0, end=5242880, size=5242880, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True)\n",
      "\n",
      "freed  7 max_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2) \n",
      " \t  [(0, 5242880)]\n",
      "Successful Strategy bysize (NO DDR)\n",
      "{0: ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[]), 1: ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])} 256 <hardware.DDR object at 0x7f32c2915748>\n",
      "Done schedule 2 STEPS\n",
      "**************************************************\n",
      "* GENERATING OUTPUT REPORTS\n",
      "**************************************************\n",
      "schedule_and_parallelism\n",
      "__________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "result 1\n",
      "__________\n",
      "0 ['input0'] size:1024 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:1536 remap:[] data movement:[]\n",
      "1\tmax_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1\tinput0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "\n",
      "args.fromtensorflow False\n",
      "Minimum Memory 1 ['max_pool2d0'] 1536\n",
      "input0_blob M[0,1024] Z=1024 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "max_pool2d0_blob M[1024,1536] Z=512 F=[] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "before enrich\n",
      " Nodes 4 \n",
      "  _____ \n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 3 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "after enrich\n",
      " Nodes 4 \n",
      "  _____ \n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 3 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "**************************************************\n",
      "* GENERATING OUTPUT FILES\n",
      "**************************************************\n",
      "XDNN Command file: temp_fpga_code.cmds\n",
      "XDNN JSON Report file: temp_fpga_code.cmds.json\n",
      "\n",
      "Path to generatefile exists...\n",
      "***** Inst JSON\n",
      "Encoding {'XNConv': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', 'XNDeconv': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', 'XNConvP': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h', 'XNUpload': 'id XNOp inaddr insize inchan', 'XNGather': 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment', 'XNScatter': 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment', 'XNEltwise': 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ', 'XNAvgPool': 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ', 'XNMaxPool': 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt '}\n",
      "Network 0 Memory False\n",
      "names dict_keys([])\n",
      "<class 'argparse.Namespace'>\n",
      "basic_from_node_to_code ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0\n",
      "1 [<pydot.Node object at 0x7f32e4c84ac8>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0 False False\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "[]\n",
      " command NO Good\n",
      "{'schedule': 1, 'xdnn_instr': \"# LAYER input0 ['Placeholder'] ['layer']\", 'name': 'input0', 'layer': 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ', 'xdnn_list': None, 'xdnn_kv': {}, 'ops': 0, 'type': 'Placeholder', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': [], 'outputshapes': SizeType(batches=1, channels=1, height=4, width=4), 'memory_description': 'am_to_am', 'attrs': {}}\n",
      "(\"# LAYER input0 ['Placeholder'] ['layer']\", 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      " command NO Good\n",
      "basic_from_node_to_code ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0\n",
      "1 [<pydot.Node object at 0x7f32e4cd1518>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "POOL ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "in  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) <class 'int'> SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IN_ST and OU_ST None None 0\n",
      "IN_ST and OU_ST 0 1024 0\n",
      "parameters Max [2, 2] [2, 2] [0, 0]\n",
      "XN%s %s %s %s %s %s %s %d %s %s 0 10\n",
      "POOL XN%s %s %s %s %s %s %s %d %s %s 0 \n",
      " 10 ['MaxPool', 'max_pool2d0', '2 2', '2 2', '0 0', '0x0', '4 4', 1, '0x400', '2 2']\n",
      "s  <class 'str'> MaxPool\n",
      "s  <class 'str'> max_pool2d0\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 0 0\n",
      "s  <class 'str'> 0x0\n",
      "s  <class 'str'> 4 4\n",
      "d  <class 'int'> 1\n",
      "s  <class 'str'> 0x400\n",
      "s 0 <class 'str'> 2 2\n",
      "POOL XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14]]\n",
      "True\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 4], [1, 8], [2, 1], [2, 2], [2, 4], [2, 8], [4, 1], [4, 2], [4, 4], [4, 8], [8, 1], [8, 2], [8, 4], [8, 8]]\n",
      "True\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "[['id', '2'], ['XNOp', 'XNMaxPool'], ['name', 'max_pool2d0'], ['kernel_w', '2'], ['kernel_h', '2'], ['strides_w', '2'], ['strides_h', '2'], ['paddings_w', '0'], ['paddings_h', '0'], ['inaddr', '0x0'], ['insize_w', '4'], ['insize_h', '4'], ['inchan', '1'], ['outaddr', '0x400'], ['outsize_w', '2'], ['outsize_h', '2'], ['Bypass_Perf_Opt', '0']]\n",
      "OUTPUT REPORT:\n",
      "Unsupported Layers: 1\n",
      "0) input0\n",
      "\tAttributes: (\"# LAYER input0 ['Placeholder'] ['layer']\", 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "BEFORE JSON 14 2\n",
      "***** Inst JSON Done\n",
      "***** Inst FILE\n",
      "()\n",
      "basic_from_node_to_code ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0\n",
      "1 [<pydot.Node object at 0x7f32e4cd52e8>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0 False False\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      " command NO Good\n",
      "(\"# LAYER input0 ['Placeholder'] ['layer']\", 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      " command NO Good\n",
      "else input0 # # LAYER input0 ['Placeholder'] ['layer'] input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  \n",
      "store input0 [\"# # LAYER input0 ['Placeholder'] ['layer'] input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  \"] [\"# # LAYER input0 ['Placeholder'] ['layer'] input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  \"]\n",
      "basic_from_node_to_code ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0\n",
      "1 [<pydot.Node object at 0x7f32e4cd1358>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "POOL ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "in  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) <class 'int'> SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IN_ST and OU_ST None None 0\n",
      "IN_ST and OU_ST 0 1024 0\n",
      "parameters Max [2, 2] [2, 2] [0, 0]\n",
      "XN%s %s %s %s %s %s %s %d %s %s 0 10\n",
      "POOL XN%s %s %s %s %s %s %s %d %s %s 0 \n",
      " 10 ['MaxPool', 'max_pool2d0', '2 2', '2 2', '0 0', '0x0', '4 4', 1, '0x400', '2 2']\n",
      "s  <class 'str'> MaxPool\n",
      "s  <class 'str'> max_pool2d0\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 0 0\n",
      "s  <class 'str'> 0x0\n",
      "s  <class 'str'> 4 4\n",
      "d  <class 'int'> 1\n",
      "s  <class 'str'> 0x400\n",
      "s 0 <class 'str'> 2 2\n",
      "POOL XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14]]\n",
      "True\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 4], [1, 8], [2, 1], [2, 2], [2, 4], [2, 8], [4, 1], [4, 2], [4, 4], [4, 8], [8, 1], [8, 2], [8, 4], [8, 8]]\n",
      "True\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "else max_pool2d0 2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am\n",
      "store max_pool2d0 ['2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am'] ['2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am']\n",
      "basic statistics\n",
      "Unsupported  1\n",
      "input0 (\"# LAYER input0 ['Placeholder'] ['layer']\", 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "***** Inst FILE OUT\n",
      "***** Inst COLLECT\n",
      "['# template XNConv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', '# template XNDeconv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', '# template XNConvP id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h', '# template XNUpload id XNOp inaddr insize inchan', '# template XNGather id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment', '# template XNScatter id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment', '# template XNEltwise id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ', '# template XNAvgPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ', '# template XNMaxPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1024, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=1024, name='input0_blob', memory=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=512, name='max_pool2d0_blob', memory=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=1536, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "***** COLLECT CODES 10\n",
      "# template XNConv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNDeconv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNConvP id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h\n",
      "# template XNUpload id XNOp inaddr insize inchan\n",
      "# template XNGather id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment\n",
      "# template XNScatter id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment\n",
      "# template XNEltwise id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt \n",
      "# template XNAvgPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "# template XNMaxPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am\n",
      "graphoptimization.inplace_rm(g)\n",
      "after removal\n",
      " Nodes 4 \n",
      "  _____ \n",
      "input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=1024, size=1024, extra=[1], strategy=[], layout=0, timestamp=6, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=1024, end=1536, size=512, extra=[1], strategy=[], layout=0, timestamp=7, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 3 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "Removed\n",
      " Nodes 0 \n",
      "  _____ \n",
      " Edges 0 \n",
      "  _____ \n",
      "Compiling weights from: weights\n",
      "reweight\n",
      "**************************************************\n",
      "* CLEANING PREVIOUS WEIGHTS\n",
      "**************************************************\n",
      "Weight Directory: ./weights_data\n",
      "Removed 0 weight files\n",
      "**************************************************\n",
      "**************************************************\n",
      "* WRITING WEIGHTS\n",
      "**************************************************\n",
      "Weight HDF5: ./weights_data.h5\n",
      "Weight Directory: ./weights_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing weights for 2 schedule steps: 1We have Data to write  input0 MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False) 0\n",
      "We DON'T write  ParametersLayer(type=['Placeholder'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=1024, input=[], output=[1024, [1024]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=[\"# # LAYER input0 ['Placeholder'] ['layer'] input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  \"], fpga=False, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " 2We have Data to write  max_pool2d0 MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False) 0\n",
      "We DON'T write  ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=1536, input=[1024, [1024]], output=[512, [512]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=['2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am'], fpga=True, replication=None, slice=0, padding_type='SAME', pipelined=None, parallel=[], commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "\n",
      "Done writing weights.\n",
      "SUCCESS True\n",
      "<class 'dict'>\n",
      "Compiled json code: {'network': [{'schedule': 1, 'xdnn_instr': \"# # LAYER input0 ['Placeholder'] ['layer']\", 'name': 'input0', 'layer': 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ', 'xdnn_list': None, 'xdnn_kv': {}, 'ops': 0, 'type': 'Placeholder', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': [], 'outputshapes': SizeType(batches=1, channels=1, height=4, width=4), 'memory_description': 'am_to_am', 'attrs': {}, 'active': 0}, {'schedule': 2, 'xdnn_instr': '2 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x400 2 2 0 # am_to_am', 'name': 'max_pool2d0', 'layer': 'max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched 1 Kernel [2, 2] Strides [2, 2] Padding [0, 0]', 'xdnn_list': None, 'xdnn_kv': {'id': '2', 'XNOp': 'XNMaxPool', 'name': 'max_pool2d0', 'kernel_w': '2', 'kernel_h': '2', 'strides_w': '2', 'strides_h': '2', 'paddings_w': '0', 'paddings_h': '0', 'inaddr': '0x0', 'insize_w': '4', 'insize_h': '4', 'inchan': '1', 'outaddr': '0x400', 'outsize_w': '2', 'outsize_h': '2', 'Bypass_Perf_Opt': '0'}, 'ops': 16, 'type': 'Pooling', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': ['input0'], 'outputshapes': SizeType(batches=1, channels=1, height=2, width=2), 'memory_description': 'am_to_am', 'attrs': {'full_paddings': [0, 0, 0, 0]}}], 'cmd': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /workspace/.local/share/jupyter/runtime/kernel-f368dfc3-3973-4c1b-a3dc-fd85c5527df1.json', 'arguments': {'generatefile': 'temp_fpga_code.cmds', 'pngfile': 'graph.png', 'concatstrategy': None, 'quant_cfgfile': None, 'anew': None, 'strategy': 'all', 'versionjson': None, 'lasttensorbyname': None, 'schedulefile': None, 'usedeephi': False, 'savepickle': None, 'loadpickle': None, 'dsp': 56, 'bytesperpixels': 2, 'verbose': True, 'pipelineconvmaxpool': False, 'parallelism': False, 'parallelismgraphalgorithm': 'tfs', 'parallelismstrategy': None, 'parallelread': None, 'noreplication': False, 'frontendonly': False, 'barrier': False, 'approximate': False, 'leavescalealone': False, 'memory': 5, 'ddr': 256, 'manasadebugmode': False, 'fromtensorflow': False, 'cpulayermustgo': False, 'conv_1x1_s2': False, 'poolingaround': False, 'nodynamicscaling': False, 'dedicateddsp': None, 'bridges': None, 'banditpre': None, 'godreplication': None, 'godtiling': None, 'forceweights': None, 'notcaffeanew': False, 'mixmemorystrategy': False, 'splitonly': False, 'rankdir': 'BT', 'networkfile': 'None', 'placeholdershape': None, 'weights': 'weights', 'textmode': False, 'finalnode': None, 'initialnode': None, 'manualbatch': False, 'fc': False, 'manualdeconv': False}, 'first_layer': 0, 'last_layer': 1, 'version': '2.0.0', 'env': \"environ({'CI_BUILD_UID': '35583', 'HOSTNAME': 'xirengvm096006', 'MLSUITE_ROOT': '/workspace/MLsuite', 'CI_BUILD_USER': 'jornt', 'SHELL': '/bin/bash', 'TERM': 'xterm-color', 'LIBXDNN_PATH': '/workspace/MLsuite/xfdnn/rt/libs/libxfdnn.so.2.20174', 'CI_BUILD_HOME': '/workspace', 'OLDPWD': '/workspace', 'LC_ALL': 'C', 'LIBXDNN_DIR': '/workspace/MLsuite/xfdnn/rt/libs', 'USER': 'jornt', 'http_proxy': 'http://172.19.128.4:8080', 'LD_LIBRARY_PATH': '/opt/sgxsdk/lib64::/workspace/MLsuite/ext/boost/lib:/workspace/MLsuite/ext/zmq/libs:/workspace/MLsuite/ext/hdf5/lib:/workspace/MLsuite/overlaybins/alveo-u200/runtime/lib/x86_64', 'SUDO_USER': 'root', 'SUDO_UID': '0', 'CI_BUILD_GROUP': 'hd', 'USERNAME': 'jornt', 'XBLAS_NUM_PREP_THREADS': '4', 'CI_BUILD_GID': '10115', 'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/bin:/usr/lib/go-1.10/bin', 'XCLBIN_PATH': '/workspace/MLsuite/overlaybins/alveo-u200', 'MKL_NUM_THREADS': '4', 'PWD': '/workspace/tvm_proj/tvm', 'JAVA_HOME': '/usr/lib/jvm/java-8-openjdk-amd64/jre', 'HTTPS_PROXY': 'https://172.19.128.4:8080', 'https_proxy': 'https://172.19.128.4:8080', 'XILINX_OPENCL': '/workspace/MLsuite/overlaybins/alveo-u200', 'SUDO_COMMAND': '/bin/bash', 'SHLVL': '2', 'HOME': '/workspace', 'TVM_HOME': '/workspace/tvm_proj/tvm', 'HTTP_PROXY': 'http://172.19.128.4:8080', 'PYTHONPATH': '/workspace/tvm_proj/tvm/python:/workspace/tvm_proj/tvm/topi/python:/workspace/tvm_proj/tvm/nnvm/python:/workspace/tvm_proj/tvm/vta/python:/workspace/tvm_proj/tvm/xdnn/python:/workspace/MLsuite:/workspace/MLsuite/xfdnn/rt:/workspace/MLsuite/ext:/workspace/MLsuite/models/darknet/tools:/workspace/MLsuite/apps/yolo:/workspace/MLsuite/apps/yolo/nms:/workspace/MLsuite/xfdnn/tools/emu:/workspace/MLsuite/xfdnn/tools/compile/network:/workspace/MLsuite/xfdnn/tools/compile/graph:/workspace/MLsuite/xfdnn/tools/compile/optimizations:/workspace/MLsuite/xfdnn/tools/compile/codegeneration:/workspace/MLsuite/xfdnn/tools/compile/memory:/workspace/MLsuite/xfdnn/tools/compile/version:/workspace/MLsuite/xfdnn/tools/compile/memory:/workspace/MLsuite/xfdnn/tools/compile/weights:/workspace/MLsuite/xfdnn/tools/compile/bin:/workspace/MLsuite/xfdnn/tools/compile/parallel:/workspace/MLsuite/xfmlp/python', 'LOGNAME': 'jornt', 'SDACCEL_INI_PATH': '/workspace/MLsuite/overlaybins', 'OMP_NUM_THREADS': '4', 'SUDO_GID': '0', '_': '/usr/local/bin/jupyter', 'JPY_PARENT_PID': '22085', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'XDNN_VERBOSE': '1'})\", 'inputddr': 0, 'outputddr': 0, 'inputs': [], 'outputs': [], 'unsupported': {'count': 1, 'list': {'input0': (\"# LAYER input0 ['Placeholder'] ['layer']\", 'input0: type=Placeholder, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')}}, 'ops': 16, 'moveops': 0}\n",
      "Max pool out: Tensor(shape=[1, 1, 2, 2], op.name=max_pool2d0)\n",
      "[1, 1, 2, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'op': 'null', 'name': 'x', 'inputs': []}, {'op': 'tvm_op', 'name': 'max_pool2d0', 'attrs': {'flatten_data': '0', 'func_name': 'fuse_max_pool2d', 'num_inputs': '1', 'num_outputs': '1'}, 'inputs': [[0, 0, 0]]}]\n",
      "Module(llvm, 46c96e0)\n",
      "{}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'xfdnn.rt.xdnn' has no attribute 'createHandle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7c15293b6e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mxdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxdnn_frontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_fpga_executer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm_proj/tvm/xdnn/python/xdnn/xdnn_frontend.py\u001b[0m in \u001b[0;36msetup_fpga_executer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mSetting\u001b[0m \u001b[0mup\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconnecion\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mFPGA\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretrieving\u001b[0m \u001b[0man\u001b[0m \u001b[0mxDNN\u001b[0m \u001b[0mexecuter\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxdnn_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_fpga_rt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m## GETTERS & SETTERS ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm_proj/tvm/xdnn/python/xdnn/xdnn_controller.py\u001b[0m in \u001b[0;36mset_fpga_rt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \" an FPGA handle\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxdnn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxclbin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xfdnn.rt.xdnn' has no attribute 'createHandle'"
     ]
    }
   ],
   "source": [
    "platform = 'alveo-u200'\n",
    "\n",
    "config = {\n",
    "    'platform': platform,\n",
    "    'xclbin': \"../../../../MLsuite/overlaybins/\" + platform + \"/overlay_3.xclbin\",\n",
    "    'memory': 5,\n",
    "    'dsp': 56,\n",
    "    'netcfg': \"work/tvm_fpga.cmds.json\",\n",
    "    #'fromtensorflow': False,\n",
    "    'weightsdir_name': \"weights\", \n",
    "    #datadir': \"work/weights_data\",\n",
    "    'quantizecfg': \"\", # Empty for now to test if quantization is needed in this simple example\n",
    "    'pngfile': \"graph.png\",\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "xdnn.xdnn_frontend.init(\n",
    "    platform=config['platform'],\n",
    "    xclbin=config['xclbin'],\n",
    "    memory=config['memory'],\n",
    "    dsp=config['dsp'],\n",
    "    netcfg=config['netcfg'],\n",
    "    weightsdir_name=config['weightsdir_name'],\n",
    "    pngfile=config['pngfile'],\n",
    "    verbose=config['verbose']\n",
    ")\n",
    "\n",
    "if EXAMPLE == 1:\n",
    "    input_shape = (1,1,4,4)\n",
    "    input_type = 'float32'\n",
    "    output_shape = (1,1,2,2)\n",
    "    \n",
    "    data = np.reshape(np.array([[1,1,0,4],[5,1,0,8],\n",
    "                                [3,5,1,0],[1,9,3,4]]), input_shape)\n",
    "    x = sb.Variable(\"x\")\n",
    "    z = sb.max_pool2d(x, pool_size=[2,2], strides=[2,2])\n",
    "    graph = nnvm.graph.create(z)\n",
    "    print(graph.index.nodes)\n",
    "    \n",
    "    print(\"\\nNNVM COMPILER BUILD\\n\")\n",
    "    \n",
    "    params = {}\n",
    "    shape_dict = { 'x': input_shape }\n",
    "    dtype_dict = { 'x': input_type }\n",
    "    graph, lib, params = nnvm.compiler.build(\n",
    "                graph, target, shape_dict, dtype_dict,\n",
    "                params=params, target_host=target_host)\n",
    "    \n",
    "    print(graph.index.nodes)\n",
    "    print(lib)\n",
    "    print(params)\n",
    "    \n",
    "    print(\"\\nXDNN SETUP FPGA EXECUTER\\n\")\n",
    "    xdnn.xdnn_frontend.setup_fpga_executer()\n",
    "    \n",
    "    print(\"\\nXDNN SETUP FPGA EXECUTER\\n\")\n",
    "    m = graph_runtime.create(graph, lib, ctx)\n",
    "    m.set_input('x', tvm.nd.array(data.astype(input_type)))\n",
    "    \n",
    "    m.run()\n",
    "    \n",
    "    tvm_output = m.get_output(0, tvm.nd.empty(((1, 1, 2, 2)), 'float32'))\n",
    "    \n",
    "    print(tvm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully created handle to FPGA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xfdnn.rt.xdnn as xdnn_lib\n",
    "\n",
    "os.environ['XDNN_VERBOSE'] = \"1\"\n",
    "\n",
    "ret, handles = xdnn_lib.createHandle(\"../../../../MLsuite/overlaybins/alveo-u200/overlay_3.xclbin\")\n",
    "\n",
    "if ret:                                                         \n",
    "    print(\"ERROR: Unable to create handle to FPGA\")\n",
    "else:\n",
    "    print(\"INFO: Successfully created handle to FPGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
