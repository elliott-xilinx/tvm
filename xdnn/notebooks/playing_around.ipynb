{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tvm\n",
    "import nnvm\n",
    "import topi\n",
    "\n",
    "import nnvm.symbol as sb\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "EXAMPLE = 1\n",
    "target, target_host = 'llvm', 'llvm'\n",
    "ctx = tvm.cpu(0)\n",
    "\n",
    "os.environ['XDNN_VERBOSE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDNN library .so file /workspace/MLsuite/xfdnn/rt/xdnn_cpp/lib/libxfdnn.so.2017.4 not found\n"
     ]
    }
   ],
   "source": [
    "import xdnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkfile None\n",
      "memory 5\n",
      "dsp 56\n",
      "generatefile work/tmp_tvm_compiler\n",
      "fromtensorflow False\n",
      "weights weights\n",
      "bytesperpixels 1\n",
      "cpulayermustgo True\n",
      "pngfile graph.png\n",
      "verbose True\n",
      "Namespace(anew=None, approximate=False, banditpre=None, barrier=False, bridges=None, bytesperpixels=1, concatstrategy=None, conv_1x1_s2=False, cpulayermustgo=True, customreplication=None, customtiling=None, cut=None, ddr=256, dedicateddsp=None, dsp=56, fancyreplications=False, fc=False, finalnode=None, forceweights=None, forceweightsfullyconnected=False, fromtensorflow=False, frontendonly=False, generatefile='work/tmp_tvm_compiler', initialnode=None, inputcut=None, laodschedule=None, lasttensorbyname=None, leavescalealone=False, loadpickle=None, manasadebugmode=None, manualbatch=False, manualdeconv=False, memory=5, mixmemorystrategy=False, networkfile='None', noconvexity=False, nodynamicscaling=False, noreplication=False, notcaffeanew=False, parallelism=False, parallelismgraphalgorithm='tfs', parallelismstrategy=None, parallelread=None, partitioning=False, pipelineconvmaxpool=False, placeholdershape=None, pngfile='graph.png', poolingaround=False, quant_cfgfile=None, quantz=None, rankdir='BT', savepickle=None, saveschedule=None, scalepipeline=False, schedulefile=None, splitonly=False, strategy='all', textmode=False, usedeephi=False, verbose=True, versionjson=None, weights='weights')\n",
      "Network: None\n",
      "GenerateCode: work/tmp_tvm_compiler\n",
      "Weights: weights\n",
      "PngFile: graph.png\n",
      "ConcatStrategy: None\n",
      "Strategy: all\n",
      "ScheduleFile: None\n",
      "DDR: 256\n",
      "DSP: 56\n",
      "DSP V2\n",
      "Verbose: True\n",
      "FromTF: False\n",
      "Memory: 5\n",
      "**************************************************\n",
      "* HARDWARE\n",
      "**************************************************\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DDR INPUT  NONE\n",
      "==========\n",
      "DDR OUTPUT NONE\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      1\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         0\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNInner', 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "[{'op': 'null', 'name': 'x', 'inputs': []}, {'op': 'max_pool2d', 'name': 'max_pool2d0', 'attrs': {'pool_size': '[2, 2]', 'strides': '[2, 2]'}, 'inputs': [[0, 0, 0]]}]\n",
      "\n",
      "NNVM COMPILER BUILD\n",
      "\n",
      "<class 'nnvm.top.attr_dict.AttrDict'>\n",
      "['input0']\n",
      "max_pool2d max_pool2d0 {'padding': '[0,0]', 'pool_size': '[2,2]', 'ceil_mode': '0', 'strides': '[2,2]', 'layout': 'NCHW'} ['input0'] [[1, 1, 4, 4], [1, 1, 2, 2]] NCHW {}\n",
      "Start transformation to xfDNN IR of:\t input0\n",
      "Node shape:\t SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Start transformation to xfDNN IR of:\t max_pool2d0\n",
      "Node shape:\t SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Creating blob:\t input0\n",
      "Creating blob:\t max_pool2d0\n",
      "\n",
      "Building graph edges\n",
      "Name:  input0 \tLayer type:  ['Input']\n",
      "Name:  max_pool2d0 \tLayer type:  ['Pooling']\n",
      "Writing graph visualization to from_nnvm_graph.png\n",
      "**************************************************\n",
      "* XFDNN GRAPH SCHEDULE\n",
      "**************************************************\n",
      "inferred\n",
      "{1} -|-0 name input0 type Input fpga True bottoms [] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "DSP: 56\n",
      "DSP V2\n",
      "Memory: 5\n",
      "DDR: 256\n",
      "**************************************************\n",
      "* HARDWARE \n",
      "**************************************************\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DDR INPUT  NONE\n",
      "==========\n",
      "DDR OUTPUT NONE\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      1\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         0\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNInner', 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "**************************************************\n",
      "* CONVERTING GRAPH TO SCHEDULE\n",
      "**************************************************\n",
      "('## Schedule', 2, 2)\n",
      "(0, \"['input0']\")\n",
      "(1, \"['max_pool2d0']\")\n",
      "(0, 'input0')\n",
      "(1, 'max_pool2d0')\n",
      "**************************************************\n",
      "* Graph Manipulations\n",
      "**************************************************\n",
      "input0\n",
      "inshapes dict_keys([])\n",
      "outshapes dict_keys(['input0_blob'])\n",
      "max_pool2d0\n",
      "inshapes dict_keys(['input0_blob'])\n",
      "outshapes dict_keys(['max_pool2d0_blob'])\n",
      "inshapes SizeType(batches=1, channels=1, height=4, width=4)\n",
      "outshapes SizeType(batches=1, channels=1, height=2, width=2)\n",
      "P.kernel_sizes [2, 2]\n",
      "padding_type max_pool2d0 VALID\n",
      "input0_blob\n",
      "inshapes dict_keys(['input0_blob'])\n",
      "outshapes dict_keys(['max_pool2d0_blob'])\n",
      "max_pool2d0_blob\n",
      "inshapes dict_keys(['max_pool2d0_blob'])\n",
      "outshapes dict_keys([])\n",
      "<class 'argparse.Namespace'>\n",
      "{'generatefile': 'work/tmp_tvm_compiler', 'pngfile': 'graph.png', 'concatstrategy': None, 'quant_cfgfile': None, 'anew': None, 'strategy': 'all', 'versionjson': None, 'lasttensorbyname': None, 'schedulefile': None, 'usedeephi': False, 'inputcut': None, 'cut': None, 'quantz': None, 'savepickle': None, 'loadpickle': None, 'dsp': 56, 'bytesperpixels': 1, 'verbose': True, 'pipelineconvmaxpool': False, 'scalepipeline': False, 'parallelism': False, 'parallelismgraphalgorithm': 'tfs', 'parallelismstrategy': None, 'parallelread': None, 'noreplication': False, 'fancyreplications': False, 'frontendonly': False, 'barrier': False, 'approximate': False, 'leavescalealone': False, 'memory': 5, 'ddr': 256, 'manasadebugmode': None, 'fromtensorflow': False, 'cpulayermustgo': True, 'noconvexity': False, 'saveschedule': None, 'laodschedule': None, 'partitioning': False, 'conv_1x1_s2': False, 'poolingaround': False, 'nodynamicscaling': False, 'dedicateddsp': None, 'bridges': None, 'banditpre': None, 'customreplication': None, 'customtiling': None, 'forceweights': None, 'notcaffeanew': False, 'forceweightsfullyconnected': False, 'mixmemorystrategy': False, 'splitonly': False, 'rankdir': 'BT', 'networkfile': 'None', 'placeholdershape': None, 'weights': 'weights', 'textmode': False, 'finalnode': None, 'initialnode': None, 'manualbatch': False, 'fc': False, 'manualdeconv': False}\n",
      "**************************************************\n",
      "* Graph weight manipulation\n",
      "**************************************************\n",
      "node_ReLU_collapse_rm\n",
      "Writing graph visualization to ./original_beforememory.png\n",
      "\n",
      "**************************************************\n",
      "* Concat Alignment verification to mod 8             \n",
      "**************************************************\n",
      "**************************************************\n",
      "* CPU Layer will be REMOVED\n",
      "**************************************************\n",
      "slice -1\n",
      "Input\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 629145600): MemoryAllocation(start=0, end=629145600, size=629145600, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), (0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "slice -1\n",
      "Output\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 629145600): MemoryAllocation(start=0, end=629145600, size=629145600, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), (0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "Map \n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "Input\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 629145600): MemoryAllocation(start=0, end=629145600, size=629145600, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), (0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "Output\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 629145600): MemoryAllocation(start=0, end=629145600, size=629145600, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), (0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      1\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         0\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNInner', 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "* CPU Layer schedule\n",
      "inferred\n",
      "{1} -|-0 name input0 type Input fpga True bottoms [] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "Convexity True\n",
      "\n",
      " convex_fpga \n",
      "\n",
      "After Convexity\n",
      "input0 True\n",
      "input0 True\n",
      "max_pool2d0 True\n",
      "max_pool2d0 True\n",
      "output max_pool2d0_output 1.5\n",
      "\n",
      "Every time we say goodbye to CPU Layer\n",
      "\n",
      "* Without CPU Layer schedule\n",
      "inferred\n",
      "{1} -|-0 name input0 type Input fpga True bottoms [] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-2 name max_pool2d0_output type Output fpga True bottoms ['max_pool2d0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "Writing graph visualization to ./nocpu.png\n",
      "\n",
      "**************************************************\n",
      "* Concat Alignment verification              \n",
      "**************************************************\n",
      "\n",
      "**************************************************\n",
      "* AVG + Scale -> AVG with different scaling  \n",
      "**************************************************\n",
      "ARGS before quantz Namespace(anew=None, approximate=False, banditpre=None, barrier=False, bridges=None, bytesperpixels=1, concatstrategy=None, conv_1x1_s2=False, cpulayermustgo=True, customreplication=None, customtiling=None, cut=None, ddr=256, dedicateddsp=None, dsp=56, fancyreplications=False, fc=False, finalnode=None, forceweights=None, forceweightsfullyconnected=False, fromtensorflow=False, frontendonly=False, generatefile='work/tmp_tvm_compiler', initialnode=None, inputcut=None, laodschedule=None, lasttensorbyname=None, leavescalealone=False, loadpickle=None, manasadebugmode=None, manualbatch=False, manualdeconv=False, memory=5, mixmemorystrategy=False, networkfile='None', noconvexity=False, nodynamicscaling=False, noreplication=False, notcaffeanew=False, parallelism=False, parallelismgraphalgorithm='tfs', parallelismstrategy=None, parallelread=None, partitioning=False, pipelineconvmaxpool=False, placeholdershape=None, pngfile='graph.png', poolingaround=False, quant_cfgfile=None, quantz=None, rankdir='BT', savepickle=None, saveschedule=None, scalepipeline=False, schedulefile=None, splitonly=False, strategy='all', textmode=False, usedeephi=False, verbose=True, versionjson=None, weights='weights')\n",
      "inferred\n",
      "{1} -|-0 name input0 type Input fpga True bottoms [] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-2 name max_pool2d0_output type Output fpga True bottoms ['max_pool2d0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "Writing graph visualization to graph.png\n",
      "Optimizing 1 schedules\n",
      "Schedule inferred\n",
      "inferred\n",
      "{1} -|-0 name input0 type Input fpga True bottoms [] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-1 name max_pool2d0 type Pooling fpga True bottoms ['input0'] [Extras None]-  Past [] -> Future []\n",
      "{1} -|-2 name max_pool2d0_output type Output fpga True bottoms ['max_pool2d0'] [Extras None]-  Past [] -> Future []\n",
      "####################################\n",
      "**************************************************\n",
      "* COMPUTING MEMORY REQUIREMENTS\n",
      "**************************************************\n",
      "standard_schedule_min_memory 3 <class 'dagtools_type.Schedule'>\n",
      "Schedule for initialization {0: ['input0'], 1: ['max_pool2d0'], 2: ['max_pool2d0_output']}\n",
      "Schedule for initialization {'input0': 0, 'max_pool2d0': 1, 'max_pool2d0_output': 2}\n",
      "Schedule for initialization nodes matches  3\n",
      "initializing  input0_blob\n",
      "input0_blob [LayerParameter=ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None), fillcolor=\"#E0E0E0\", shape=octagon, style=filled];\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 512 UUUUU\n",
      "512 SizeType(batches=1, channels=1, height=4, width=4)\n",
      "IO @@@ input0_blob MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "initializing  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "initialized blob input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None) ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[])\n",
      "initializing  max_pool2d0_blob\n",
      "max_pool2d0_blob [LayerParameter=ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}), fillcolor=\"#E0E0E0\", shape=octagon, style=filled];\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 256 UUUUU\n",
      "256 SizeType(batches=1, channels=1, height=2, width=2)\n",
      "initializing  ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "initialized blob max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0]) ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[])\n",
      "initializing  max_pool2d0_output_blob\n",
      "max_pool2d0_output_blob [LayerParameter=ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}), fillcolor=\"#E0E0E0\", shape=octagon, style=filled];\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=None, systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_output_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 256 UUUUU\n",
      "256 SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IO @@@ max_pool2d0_output_blob MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "initializing  ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "initialized blob max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0]) ColorForDAG(active=[0], schedule=-1, forward=[], backward=[2], extra=None, hook=[])\n",
      "Schedule for initialization blobs matches  3\n",
      "2 YYYYYYY\n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None) ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[])\n",
      "\t input MemoryRequirements(size=0, input=[], output=[], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t O input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 512 UUUUU\n",
      "\t output MemoryRequirements(size=0, input=[], output=[512, [512]], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t overall MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "initialize layer input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None) ColorForDAG(active=[0], schedule=0, forward=[1], backward=[], extra=None, hook=[])\n",
      "2 YYYYYYY\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=1, forward=[2], backward=[0], extra=None, hook=[])\n",
      "\t I input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "input0_blob 2 SizeType(batches=1, channels=1, height=4, width=4) 512 UUUUU\n",
      "\t input MemoryRequirements(size=0, input=[512, [512]], output=[], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t O max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 256 UUUUU\n",
      "\t output MemoryRequirements(size=0, input=[512, [512]], output=[256, [256]], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t overall MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "initialize layer max_pool2d0 max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=1, forward=[2], backward=[0], extra=None, hook=[])\n",
      "2 YYYYYYY\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=2, forward=[], backward=[1], extra=None, hook=[])\n",
      "\t I max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 256 UUUUU\n",
      "\t input MemoryRequirements(size=0, input=[256, [256]], output=[], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t O max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      "2 ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[0], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "max_pool2d0_output_blob 2 SizeType(batches=1, channels=1, height=2, width=2) 256 UUUUU\n",
      "\t output MemoryRequirements(size=0, input=[256, [256]], output=[256, [256]], internal=[], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "\t overall MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False)\n",
      "initialize layer max_pool2d0_output max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[0], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0]) ColorForDAG(active=[0], schedule=2, forward=[], backward=[1], extra=None, hook=[])\n",
      "Initialization Done\n",
      "Is  []\n",
      "step 0 ['input0']\n",
      "step name 0 input0\n",
      "step dagnode 0 input0\n",
      "active layer  input0 ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None) input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "\t\t activated ->  input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "step _ 0 {'input0_blob': BlobInformation(size=0, name='input0_blob', memory=None, dag=ColorForDAG(active=[1], schedule=0, forward=[1], backward=[], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "INFO ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "memory 0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "step 1 ['max_pool2d0']\n",
      "step name 1 max_pool2d0\n",
      "step dagnode 1 max_pool2d0\n",
      "active layer  max_pool2d0 ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[1], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "\t\t activated ->  max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "step _ 1 {'input0_blob': BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), 'max_pool2d0_blob': BlobInformation(size=0, name='max_pool2d0_blob', memory=None, dag=ColorForDAG(active=[1], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "INFO ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "memory 1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "\t\t ### deactivated ->  input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None) ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[])\n",
      "step 2 ['max_pool2d0_output']\n",
      "step name 2 max_pool2d0_output\n",
      "step dagnode 2 max_pool2d0_output\n",
      "active layer  max_pool2d0_output ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "\t\t activated ->  max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      "step _ 2 {'max_pool2d0_blob': BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), 'max_pool2d0_output_blob': BlobInformation(size=0, name='max_pool2d0_output_blob', memory=None, dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "INFO ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "memory 2 ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[1], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[1], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "\t\t ### deactivated ->  max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0]) ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[])\n",
      "\t\t ### deactivated ->  max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      "{0: ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[]), 1: ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=[], data_movement_operation_costs=[]), 2: ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])}\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "2 ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      " Nodes 6 \n",
      "  _____ \n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 5 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "max_pool2d0_blob -> max_pool2d0_output  [label=\"max_pool2d0->max_pool2d0_output\"];\n",
      "max_pool2d0_output -> max_pool2d0_output_blob  [label=\"max_pool2d0_output->max_pool2d0_output_blob\"];\n",
      "Memory Schedule 3\n",
      "__________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:[]\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "__________\n",
      "2 ['max_pool2d0_output'] size:512 remap:[] data movement:[]\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "\n",
      "__________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:[]\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "__________\n",
      "2 ['max_pool2d0_output'] size:512 remap:[] data movement:[]\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "\n",
      "Minimum Memory __________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:[]\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      " Nodes 6 \n",
      "  _____ \n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 5 \n",
      "  _____ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "max_pool2d0_blob -> max_pool2d0_output  [label=\"max_pool2d0->max_pool2d0_output\"];\n",
      "max_pool2d0_output -> max_pool2d0_output_blob  [label=\"max_pool2d0_output->max_pool2d0_output_blob\"];\n",
      "MAX  1\n",
      "TOP 5\n",
      "__________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:[]\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "__________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "2 ['max_pool2d0_output'] size:512 remap:[] data movement:[]\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Using Hardware Version [2]\n",
      "**************************************************\n",
      "* ALLOCATING DYNAMIC MEMORY SCHEDULE\n",
      "**************************************************\n",
      "Allocating Memory all\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "Input\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "Output\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      1\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         8\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNInner', 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "Trying no-DDR strategies...\n",
      "You tell me there must be DDR, Skip the AM only\n",
      "None 256 <hardware.DDR object at 0x7f4ada97e748>\n",
      "Trying DDR strategies with 0 MB ...\n",
      "Reset Memory\n",
      "Trying strategy bysize (DDR: 0 MB)\n",
      "Performing two level schedule strategy all\n",
      "Reference None\n",
      "boundary 512 strategy bysize\n",
      "Initial memory map \n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 0): MemoryAllocation(start=0, end=0, size=0, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              0\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "Input\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "Output\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      1\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "\t self.frequency           700000000.0\n",
      "\t self.efficiency          0.7\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         8\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    1\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNInner', 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "##########\n",
      "\n",
      "Input & outputs input0 ['Input']\n",
      "\t dict_keys([])\n",
      "\t dict_keys(['max_pool2d0'])\n",
      "Input & outputs max_pool2d0_output ['Output']\n",
      "\t dict_keys(['max_pool2d0'])\n",
      "\t dict_keys([])\n",
      "outs 1\n",
      "inss 1\n",
      " ?????  <hardware.DDR object at 0x7f4ada997278> <hardware.DDR object at 0x7f4b040ab240>\n",
      "DDR allocate x MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "rule3\n",
      "rule3\n",
      "Batches 1\n",
      " num_bytes_ddr SizeType(batches=1, channels=1, height=4, width=4)\n",
      " num_bytes_ddr Input\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         1\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "32 4 1 64 1 256 4 4 64 2\n",
      "DDR allocate r SpaceAndTime(space=512, time=1, replication=None)\n",
      "DDR allocate x MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "allocate MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bottom ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bottom MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) [(0, 268435456)]\n",
      " slot  MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 268434944 END Address 268435968\n",
      "found ref MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "input0_blob new MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True)\n",
      "DDR allocate x MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "rule3\n",
      "rule3\n",
      "Batches 1\n",
      " num_bytes_ddr SizeType(batches=1, channels=1, height=2, width=2)\n",
      " num_bytes_ddr Output\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         1\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule3\n",
      "\t self.frequency           300000000.0\n",
      "\t self.efficiency          0.9\n",
      "\t self.batches             4\n",
      "\t self.dsp 96\n",
      "32 4 1 64 1 128 2 2 64 2\n",
      "DDR allocate r SpaceAndTime(space=256, time=1, replication=None)\n",
      "DDR allocate x MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True)\n",
      "allocate MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) bottom ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bottom MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True) [(0, 268435456)]\n",
      " slot  MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 268435200 END Address 268435712\n",
      "found ref MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "max_pool2d0_output_blob new MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True)\n",
      "Alive  input0_blob BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "Alive  max_pool2d0_output_blob BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "RUNNING STEP 0\n",
      "Beginning step 0 __________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "Remappping None\n",
      "Concat None\n",
      "LOOPING ACTIVE NODES...\n",
      "Node:  ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "layername input0 set(tick)  ['input0_blob']  input  []  output  ['input0_blob']\n",
      "Done I instruction:inputs  [] outputs [0] call input0\n",
      "None\n",
      "BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "datamovements [] []\n",
      "step datamovemements [] []\n",
      "LOOPING ACTIVE NODES DEACTIVATION...\n",
      "RUNNING STEP 1\n",
      "Beginning step 1 __________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:[]\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Remappping None\n",
      "Concat None\n",
      "LOOPING ACTIVE NODES...\n",
      "Node:  ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "layername max_pool2d0 set(tick)  ['input0_blob', 'max_pool2d0_blob']  input  ['input0_blob']  output  ['max_pool2d0_blob']\n",
      "layername max_pool2d0 set(tick)  ['input0_blob', 'max_pool2d0_blob']  input  ['input0_blob']  output  ['max_pool2d0_blob']\n",
      "active blobs in step [BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])]\n",
      "active names in step ['max_pool2d0']\n",
      "live names\n",
      " input0_blob : BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])Active \n",
      "max_pool2d0_output_blob : BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])Active \n",
      "max_pool2d0_blob : BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "max_pool2d0_blob\n",
      "outputs max_pool2d0_blob MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "inputs input0_blob MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True)\n",
      "same rules 1\n",
      "same rules range(1, 1)\n",
      "Memory Count {0: 0} 0 BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "slice_abstraction_size 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "Memory Count {0: 512} 0 BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "slice_abstraction_size 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "SIZE 0 {0: 768} [0, 5242880]\n",
      "in_ddr True 768 5242880 0 0\n",
      "in_ddr 0 0 3 2 None am_to_am True False False True\n",
      "0 TEMP blob tick  input0_blob BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "allocate_am 0 512\n",
      "slice allocate 512\n",
      "AM allocate 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=4, width=4) 56\n",
      "AM allocate SpaceAndTime(space=512, time=11, replication=None)\n",
      "AM allocate before MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True) bysize\n",
      "allocate MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True) bysize ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bysize MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True) [(0, 5242880)]\n",
      " slot  MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 5242368 END Address 5243392\n",
      "found ref MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "downcommand True MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False) 0 0 4 4 1 0 3 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0) 0 input0_blob\n",
      "TEMP Touch ?: False\n",
      "BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_operation_costs=[512])\n",
      "TEMP blob data movement ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob']\n",
      "TEMP data movement []\n",
      "TEMP blob data movement costs [512]\n",
      "TEMP data movement []\n",
      "blob BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Input', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "TEMP newblob BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_operation_costs=[512])\n",
      "0 TEMP blob tick  max_pool2d0_blob BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "allocate_am 0 256\n",
      "slice allocate 256\n",
      "AM allocate 0 Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0)\n",
      " num_bytes_uram SizeType(batches=1, channels=1, height=2, width=2) 56\n",
      "AM allocate SpaceAndTime(space=256, time=12, replication=None)\n",
      "AM allocate before MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) bysize\n",
      "allocate MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) bysize ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "fitting bysize MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) [(512, 5242880)]\n",
      " slot  MemoryAllocation(start=512, end=5242880, size=5242368, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False) \n",
      " SIZE 5242112 END Address 5243136\n",
      "found ref MemoryAllocation(start=512, end=5242880, size=5242368, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "TEMP Touch ?: False\n",
      "BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "TEMP blob data movement []\n",
      "TEMP data movement ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob']\n",
      "TEMP blob data movement costs []\n",
      "TEMP data movement [512]\n",
      "blob BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "TEMP newblob BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "We can compute because everything is in URAM\n",
      "Done instruction:inputs  [0] outputs [512] call max_pool2d0\n",
      "tick BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_operation_costs=[512])\n",
      "tick BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "datamovements ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'] [512, 0]\n",
      "step datamovemements ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'] [512, 0]\n",
      "LOOPING ACTIVE NODES DEACTIVATION...\n",
      "M checking for deallocation  False A False B True C True BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "M deleted LFnames  input0_blob input0_blob\n",
      "FREE SPACE (0, 512)-MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False)\n",
      "(768, 5242880)-MemoryAllocation(start=768, end=5242880, size=5242112, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "\n",
      "M freed  1 1 input0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "RUNNING STEP 2\n",
      "Beginning step 2 __________\n",
      "2 ['max_pool2d0_output'] size:512 remap:[] data movement:[]\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[1] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[0,256] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Remappping None\n",
      "Concat None\n",
      "LOOPING ACTIVE NODES...\n",
      "Node:  ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "layername max_pool2d0_output set(tick)  ['max_pool2d0_blob', 'max_pool2d0_output_blob']  input  ['max_pool2d0_blob']  output  ['max_pool2d0_output_blob']\n",
      "Done I instruction:inputs  [512] outputs [0] call max_pool2d0_output\n",
      "datamovements ['call max_pool2d0_output;'] [0]\n",
      "step datamovemements ['call max_pool2d0_output;'] [0]\n",
      "LOOPING ACTIVE NODES DEACTIVATION...\n",
      "M checking for deallocation  False A False B True C True BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "M deleted LFnames  max_pool2d0_blob max_pool2d0_blob\n",
      "free right join MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False) MemoryAllocation(start=768, end=5242880, size=5242112, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)\n",
      "free left join MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False) MemoryAllocation(start=512, end=5242880, size=5242368, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False)\n",
      "FREE SPACE (0, 5242880)-MemoryAllocation(start=0, end=5242880, size=5242880, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False)\n",
      "\n",
      "M freed  1 7 max_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "M checking for deallocation  False A True B [] C True BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "M deleted LFnames  max_pool2d0_output_blob max_pool2d0_output_blob\n",
      "M freed  1 None max_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[1] S=['layer'] [] L=1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "Successful Strategy bysize (DDR: 256 MB)\n",
      "{0: ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[]), 1: ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'], data_movement_operation_costs=[512, 0]), 2: ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['call max_pool2d0_output;'], data_movement_operation_costs=[0])} 256 <hardware.DDR object at 0x7f4ada97e748>\n",
      "Done schedule 3 STEPS\n",
      "**************************************************\n",
      "* GENERATING OUTPUT REPORTS\n",
      "**************************************************\n",
      "schedule_and_parallelism\n",
      "__________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', caffename=None, input_addresses=[], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;']\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'], data_movement_operation_costs=[512, 0])\n",
      "ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "__________\n",
      "2 ['max_pool2d0_output'] size:768 remap:[] data movement:['call max_pool2d0_output;']\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[1] S=['layer'] [] L=1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2 ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['call max_pool2d0_output;'], data_movement_operation_costs=[0])\n",
      "ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "result 1\n",
      "__________\n",
      "0 ['input0'] size:512 remap:[] data movement:[]\n",
      "0\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "__________\n",
      "1 ['max_pool2d0'] size:768 remap:[] data movement:['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;']\n",
      "1\tinput0_blob M[0,512] Z=512 F=[1] B=[0] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=4, width=4)\n",
      "1\tmax_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "__________\n",
      "2 ['max_pool2d0_output'] size:768 remap:[] data movement:['call max_pool2d0_output;']\n",
      "2\tmax_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[1] S=['layer'] [] L=1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "2\tmax_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "\n",
      "args.fromtensorflow False\n",
      "Minimum Memory 2 ['max_pool2d0_output'] 768\n",
      "max_pool2d0_blob M[512,768] Z=256 F=[2] B=[1] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "max_pool2d0_output_blob M[0,256] Z=256 F=[] B=[2] E=[1] S=['layer'] [] L=1 T=SizeType(batches=1, channels=1, height=2, width=2)\n",
      "before enrich\n",
      " Nodes 6 \n",
      "  _____ \n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 5 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "max_pool2d0_blob -> max_pool2d0_output  [label=\"max_pool2d0->max_pool2d0_output\"];\n",
      "max_pool2d0_output -> max_pool2d0_output_blob  [label=\"max_pool2d0_output->max_pool2d0_output_blob\"];\n",
      "after enrich\n",
      " Nodes 6 \n",
      "  _____ \n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 5 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "max_pool2d0_blob -> max_pool2d0_output  [label=\"max_pool2d0->max_pool2d0_output\"];\n",
      "max_pool2d0_output -> max_pool2d0_output_blob  [label=\"max_pool2d0_output->max_pool2d0_output_blob\"];\n",
      "**************************************************\n",
      "* GENERATING OUTPUT FILES\n",
      "**************************************************\n",
      "XDNN Command file: work/tmp_tvm_compiler\n",
      "XDNN JSON Report file: work/tmp_tvm_compiler.json\n",
      "work\n",
      "Path to generatefile exists...\n",
      "***** Inst JSON\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding {'XNConv': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', 'XNDeconv': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', 'XNConvP': 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h', 'XNUpload': 'id XNOp inaddr insize inchan', 'XNInner': 'id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth', 'XNGather': 'id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment', 'XNScatter': 'id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment', 'XNEltwise': 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ', 'XNAvgPool': 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ', 'XNMaxPool': 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt '}\n",
      "Network 0 Memory False\n",
      "names dict_keys([])\n",
      "[1] <class 'argparse.Namespace'>\n",
      "basic_from_node_to_code ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', caffename=None, input_addresses=[], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0\n",
      "1 [<pydot.Node object at 0x7f4b040e6860>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "Input NODE input0 ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0', caffename=None, input_addresses=[], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "datamove XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "[['id', '1'], ['XNOp', 'XNGather'], ['uram_dest', '0x0'], ['ddr_src', '0x0'], ['insize_w', '4'], ['insize_h', '4'], ['inchan', '1'], ['a0', '0'], ['b1', '1'], ['c1', '1'], ['start_row', '0'], ['end_row', '3'], ['slice', '0'], ['srcAddrReadFromImgQ', '1'], ['sep', '#'], ['comment', 'Input']]\n",
      "generate json >>>>>### ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'] [512, 0]\n",
      "[['id', '2'], ['XNOp', 'XNGather'], ['uram_dest', '0x0'], ['ddr_src', '0x0'], ['insize_w', '4'], ['insize_h', '4'], ['inchan', '1'], ['a0', '0'], ['b1', '1'], ['c1', '1'], ['start_row', '0'], ['end_row', '3'], ['slice', '0'], ['srcAddrReadFromImgQ', '1'], ['sep', '#'], ['comment', 'input0_blob']]\n",
      "Changing input0_blob\n",
      "[{'schedule': 1, 'xdnn_instr': '1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0', 'name': 'input0', 'layer': 'input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE', 'xdnn_list': None, 'xdnn_kv': {'id': '1', 'XNOp': 'XNGather', 'uram_dest': '0x0', 'ddr_src': '0x0', 'insize_w': '4', 'insize_h': '4', 'inchan': '1', 'a0': '0', 'b1': '1', 'c1': '1', 'start_row': '0', 'end_row': '3', 'slice': '0', 'srcAddrReadFromImgQ': '1', 'sep': '#', 'comment': 'Input'}, 'ops': 512, 'type': 'Input', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': [], 'outputshapes': SizeType(batches=1, channels=1, height=4, width=4), 'memory_description': 'am_to_am', 'merged': ['input0'], 'attrs': {}, 'active': 0}] input0 ['Input']\n",
      "Input\n",
      "First Changing Found {'schedule': 1, 'xdnn_instr': '1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0', 'name': 'input0', 'layer': 'input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE', 'xdnn_list': None, 'xdnn_kv': {'id': '1', 'XNOp': 'XNGather', 'uram_dest': '0x0', 'ddr_src': '0x0', 'insize_w': '4', 'insize_h': '4', 'inchan': '1', 'a0': '0', 'b1': '1', 'c1': '1', 'start_row': '0', 'end_row': '3', 'slice': '0', 'srcAddrReadFromImgQ': '1', 'sep': '#', 'comment': 'Input'}, 'ops': 512, 'type': 'Input', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': [], 'outputshapes': SizeType(batches=1, channels=1, height=4, width=4), 'memory_description': 'am_to_am', 'merged': ['input0'], 'attrs': {}, 'active': 0}\n",
      "Changing Found {'schedule': 1, 'xdnn_instr': '2 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'name': 'input0', 'layer': 'input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE', 'xdnn_list': None, 'xdnn_kv': {'id': '2', 'XNOp': 'XNGather', 'uram_dest': '0x0', 'ddr_src': '0x0', 'insize_w': '4', 'insize_h': '4', 'inchan': '1', 'a0': '0', 'b1': '1', 'c1': '1', 'start_row': '0', 'end_row': '3', 'slice': '0', 'srcAddrReadFromImgQ': '1', 'sep': '#', 'comment': 'input0_blob'}, 'ops': 512, 'type': 'Input', 'deeppy': DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), 'bottoms': [], 'outputshapes': SizeType(batches=1, channels=1, height=4, width=4), 'memory_description': 'am_to_am', 'merged': ['input0'], 'attrs': {}, 'active': 1, 'contribute': 'input0'}\n",
      "basic_from_node_to_code ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0\n",
      "1 [<pydot.Node object at 0x7f4b03fd3470>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "POOL ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "in  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) <class 'int'> SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IN_ST and OU_ST [0] [512] 0\n",
      "IN_ST and OU_ST 0 512 0\n",
      "parameters Max [2, 2] [2, 2] [0, 0]\n",
      "XN%s %s %s %s %s %s %s %d %s %s 0 10\n",
      "POOL XN%s %s %s %s %s %s %s %d %s %s 0 \n",
      " 10 ['MaxPool', 'max_pool2d0', '2 2', '2 2', '0 0', '0x0', '4 4', 1, '0x200', '2 2']\n",
      "s  <class 'str'> MaxPool\n",
      "s  <class 'str'> max_pool2d0\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 0 0\n",
      "s  <class 'str'> 0x0\n",
      "s  <class 'str'> 4 4\n",
      "d  <class 'int'> 1\n",
      "s  <class 'str'> 0x200\n",
      "s 0 <class 'str'> 2 2\n",
      "POOL XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14]]\n",
      "True\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 4], [1, 8], [2, 1], [2, 2], [2, 4], [2, 8], [4, 1], [4, 2], [4, 4], [4, 8], [8, 1], [8, 2], [8, 4], [8, 8]]\n",
      "True\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "[['id', '1'], ['XNOp', 'XNMaxPool'], ['name', 'max_pool2d0'], ['kernel_w', '2'], ['kernel_h', '2'], ['strides_w', '2'], ['strides_h', '2'], ['paddings_w', '0'], ['paddings_h', '0'], ['inaddr', '0x0'], ['insize_w', '4'], ['insize_h', '4'], ['inchan', '1'], ['outaddr', '0x200'], ['outsize_w', '2'], ['outsize_h', '2'], ['Bypass_Perf_Opt', '0']]\n",
      "generate json >>>>>### ['call max_pool2d0_output;'] [0]\n",
      "basic_from_node_to_code ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0_output\n",
      "1 [<pydot.Node object at 0x7f4b040cbac8>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "Output NODE max_pool2d0_output ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "input 512 [512] MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False) ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "512 0 2 2 1 0 1 0 Output max_pool2d0_output\n",
      "datamove XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      "[['id', '2'], ['XNOp', 'XNScatter'], ['uram_src', '0x200'], ['ddr_dest', '0x0'], ['outsize_w', '2'], ['outsize_h', '2'], ['outchan', '1'], ['a0', '0'], ['b1', '1'], ['c1', '1'], ['start_row', '0'], ['end_row', '1'], ['slice', '0'], ['destAddrReadFromImgQ', '1'], ['sep', '#'], ['comment', 'Output']]\n",
      "output ddr {(256, 268435456): MemoryAllocation(start=256, end=268435456, size=268435200, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "input ddr {(512, 268435456): MemoryAllocation(start=512, end=268435456, size=268434944, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='', IO=False)}\n",
      "OUTPUT REPORT:\n",
      "Unsupported Layers: 0\n",
      "BEFORE JSON 15 3\n",
      "***** Inst JSON Done\n",
      "***** Inst FILE\n",
      "()\n",
      "basic_from_node_to_code ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=-1, scaling=None, data=None, name='input0', caffename=None, input_addresses=[0], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "input0\n",
      "1 [<pydot.Node object at 0x7f4b040847b8>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "Input NODE input0 ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=-1, scaling=None, data=None, name='input0', caffename=None, input_addresses=[0], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "datamove XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      " command NO Good\n",
      "('1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0', 'input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE')\n",
      " command NO Good\n",
      "else input0 # 1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE\n",
      "store input0 ['# 1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE'] ['# 1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE']\n",
      "generate >>>>>### ['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;']\n",
      "basic_from_node_to_code ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0\n",
      "1 [<pydot.Node object at 0x7f4ada928320>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "POOL ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "in  ParametersLayer(type=None, number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=[16], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=None, scaling=None, data=None, name='input0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]}) <class 'int'> SizeType(batches=1, channels=1, height=2, width=2)\n",
      "IN_ST and OU_ST [0] [512] 0\n",
      "IN_ST and OU_ST 0 512 0\n",
      "parameters Max [2, 2] [2, 2] [0, 0]\n",
      "XN%s %s %s %s %s %s %s %d %s %s 0 10\n",
      "POOL XN%s %s %s %s %s %s %s %d %s %s 0 \n",
      " 10 ['MaxPool', 'max_pool2d0', '2 2', '2 2', '0 0', '0x0', '4 4', 1, '0x200', '2 2']\n",
      "s  <class 'str'> MaxPool\n",
      "s  <class 'str'> max_pool2d0\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 2 2\n",
      "s  <class 'str'> 0 0\n",
      "s  <class 'str'> 0x0\n",
      "s  <class 'str'> 4 4\n",
      "d  <class 'int'> 1\n",
      "s  <class 'str'> 0x200\n",
      "s 0 <class 'str'> 2 2\n",
      "POOL XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14]]\n",
      "True\n",
      "[2, 2]\n",
      "[[1, 1], [1, 2], [1, 4], [1, 8], [2, 1], [2, 2], [2, 4], [2, 8], [4, 1], [4, 2], [4, 4], [4, 8], [8, 1], [8, 2], [8, 4], [8, 8]]\n",
      "True\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      ">>>>> max_pool2d0 3 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0 # am_to_am max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched 1 Kernel [2, 2] Strides [2, 2] Padding [0, 0] 0\n",
      "store max_pool2d0 ['2 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob ', '3 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0 # am_to_am'] ['2 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob ', '3 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0 # am_to_am']\n",
      "generate >>>>>### ['call max_pool2d0_output;']\n",
      "basic_from_node_to_code ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=-1, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "max_pool2d0_output\n",
      "1 [<pydot.Node object at 0x7f4b03fdefd0>]\n",
      "ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "Output NODE max_pool2d0_output ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=-1, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=None, fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "input 512 [512] MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False) ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "out ParametersLayer(type=None, number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=[1, 1], quantizations=None, batches=None, layer_type=['blob'], extras_and_future=None, tops=[], bottoms=['max_pool2d0_output'], layer=[], dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0_output_blob', caffename=None, input_addresses=None, output_addresses=None, data_movements=None, data_movement_costs=None, instructions=None, fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "512 0 2 2 1 0 1 0 Output max_pool2d0_output\n",
      "datamove XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output\n",
      "DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False)\n",
      ">>>>> max_pool2d0_output 5 XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched 2 Kernel [2, 2] Strides [2, 2] Padding [0, 0] 0\n",
      "store max_pool2d0_output ['5 XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output'] ['5 XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output']\n",
      "basic statistics\n",
      "Unsupported  1\n",
      "input0 ('1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0', 'input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE')\n",
      "***** Inst FILE OUT\n",
      "***** Inst COLLECT\n",
      "['# template XNConv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', '# template XNDeconv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ', '# template XNConvP id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h', '# template XNUpload id XNOp inaddr insize inchan', '# template XNInner id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth', '# template XNGather id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment', '# template XNScatter id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment', '# template XNEltwise id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ', '# template XNAvgPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ', '# template XNMaxPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "0 ScheduleSteps(active_node_names=['input0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=512, remapping=[], data_movement_operations=[], data_movement_operation_costs=[])\n",
      "1 ScheduleSteps(active_node_names=['max_pool2d0'], active_blob_values=[BlobInformation(size=512, name='input0_blob', memory=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob', 'call max_pool2d0;'], data_movement_operation_costs=[512, 0])\n",
      "2 ScheduleSteps(active_node_names=['max_pool2d0_output'], active_blob_values=[BlobInformation(size=256, name='max_pool2d0_blob', memory=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), dag=ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[]), BlobInformation(size=256, name='max_pool2d0_output_blob', memory=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), dag=ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]), layer_type=['layer'], data_movement_operations=[], data_movement_operation_costs=[])], memory_top=768, remapping=[], data_movement_operations=['call max_pool2d0_output;'], data_movement_operation_costs=[0])\n",
      "***** COLLECT CODES 14\n",
      "# template XNConv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNDeconv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNConvP id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h\n",
      "# template XNUpload id XNOp inaddr insize inchan\n",
      "# template XNInner id XNOp name relu prelu preshift scale postshift matrixheight matrixwidthh inaddr inheight inwidth outaddr outheight outwidth\n",
      "# template XNGather id XNOp uram_dest ddr_src insize_w insize_h inchan a0 b1 c1 start_row end_row slice srcAddrReadFromImgQ sep comment\n",
      "# template XNScatter id XNOp uram_src ddr_dest outsize_w outsize_h outchan a0 b1 c1 start_row end_row slice destAddrReadFromImgQ sep comment\n",
      "# template XNEltwise id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt \n",
      "# template XNAvgPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "# template XNMaxPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "# 1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE\n",
      "2 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob \n",
      "3 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0 # am_to_am\n",
      "5 XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output\n",
      "graphoptimization.inplace_rm(g)\n",
      "after removal\n",
      " Nodes 6 \n",
      "  _____ \n",
      "input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]) back None forw ['input0'] strat None LT->['layer'] P(None)\n",
      "max_pool2d0: type=Pooling, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat None LT->['layer'] P([0, 0])\n",
      "input0_blob: type=blob, sizes=MemoryAllocation(start=0, end=512, size=512, extra=[1], strategy=[], layout=0, timestamp=11, slice=0, shapes=SizeType(batches=1, channels=1, height=4, width=4), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), shapes=SizeType(batches=1, channels=1, height=4, width=4), sched ColorForDAG(active=[3], schedule=-1, forward=[1], backward=[0], extra=None, hook=[]) back ['input0'] forw ['max_pool2d0'] strat [] LT->['blob'] P(None)\n",
      "max_pool2d0_blob: type=blob, sizes=MemoryAllocation(start=512, end=768, size=256, extra=[1], strategy=[], layout=0, timestamp=12, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=True, specifier='AM for pinky', IO=False), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[2], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat [] LT->['blob'] P([0, 0])\n",
      "max_pool2d0_output: type=Output, sizes=None, shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]) back ['max_pool2d0'] forw ['max_pool2d0_output'] strat None LT->['layer'] P([0, 0])\n",
      "max_pool2d0_output_blob: type=blob, sizes=MemoryAllocation(start=0, end=256, size=256, extra=[1], strategy=[], layout=1, timestamp=1, slice=0, shapes=SizeType(batches=1, channels=1, height=2, width=2), replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False, specifier='Output', IO=True), shapes=SizeType(batches=1, channels=1, height=2, width=2), sched ColorForDAG(active=[3], schedule=-1, forward=[], backward=[2], extra=None, hook=[]) back ['max_pool2d0_output'] forw None strat [] LT->['blob'] P([0, 0])\n",
      " Edges 5 \n",
      "  _____ \n",
      "input0 -> input0_blob  [label=\"input0->input0_blob\"];\n",
      "input0_blob -> max_pool2d0  [label=\"input0_blob->max_pool2d0\"];\n",
      "max_pool2d0 -> max_pool2d0_blob  [label=\"max_pool2d0->max_pool2d0_blob\"];\n",
      "max_pool2d0_blob -> max_pool2d0_output  [label=\"max_pool2d0->max_pool2d0_output\"];\n",
      "max_pool2d0_output -> max_pool2d0_output_blob  [label=\"max_pool2d0_output->max_pool2d0_output_blob\"];\n",
      "Removed\n",
      " Nodes 0 \n",
      "  _____ \n",
      " Edges 0 \n",
      "  _____ \n",
      "Compiling weights from: weights\n",
      "reweight\n",
      "**************************************************\n",
      "* CLEANING PREVIOUS WEIGHTS\n",
      "**************************************************\n",
      "**************************************************\n",
      "* WRITING WEIGHTS\n",
      "**************************************************\n",
      "Weight HDF5: work/weights_data.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing weights for 3 schedule steps: 1We have Data to write  input0 MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False) 0\n",
      "We DON'T write  ParametersLayer(type=['Input'], number_outputs=None, paddings=None, kernel_sizes=None, strides=None, dilation=None, group=None, global_pooling=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sizes=MemoryRequirements(size=512, input=[], output=[512, [512]], internal=[2, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['input0'], bottoms=[], layer=[], dag=ColorForDAG(active=[2], schedule=0, forward=[1], backward=[], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=None, operation=-1, scaling=None, data=None, name='input0', caffename=None, input_addresses=[0], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=['# 1 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # Input input0 input0: type=Input, sizes=None, shapes=SizeType(batches=1, channels=1, height=4, width=4), sched 0 Kernel None Strides None Padding None MUTE CODE'], fpga=True, replication=None, slice=0, padding_type=None, pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=None, attrs=None)\n",
      " 2We have Data to write  max_pool2d0 MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False) 0\n",
      "We DON'T write  ParametersLayer(type=['Pooling'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=768, input=[512, [512]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0'], bottoms=['input0'], layer=[], dag=ColorForDAG(active=[2], schedule=1, forward=[2], backward=[0], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=None, scaling=None, data=None, name='max_pool2d0', caffename=None, input_addresses=[0], output_addresses=[512], data_movements=['XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob'], data_movement_costs=[512], instructions=['2 XNGather 0x0 0x0 4 4 1 0 1 1 0 3 0 1 # input0_blob ', '3 XNMaxPool max_pool2d0 2 2 2 2 0 0 0x0 4 4 1 0x200 2 2 0 # am_to_am'], fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_am', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      " 3We have Data to write  max_pool2d0_output MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False) 0\n",
      "We DON'T write  ParametersLayer(type=['Output'], number_outputs=None, paddings=[0, 0], kernel_sizes=[2, 2], strides=[2, 2], dilation=None, group=None, global_pooling=False, shapes=SizeType(batches=1, channels=1, height=2, width=2), sizes=MemoryRequirements(size=512, input=[256, [256]], output=[256, [256]], internal=[4, []], extra=None, strategy=[], layout=-1, timestamp=-1, shapes=None, replication=None, written=False, specifier='', IO=False), quantizations=None, batches=None, layer_type=['layer'], extras_and_future=None, tops=['max_pool2d0_output'], bottoms=['max_pool2d0'], layer=[], dag=ColorForDAG(active=[1], schedule=2, forward=[], backward=[1], extra=None, hook=[]), systolic_width=56, word_width=64, alignedsizes=None, bias=None, scale=None, preshift=None, postshift=None, posscale=None, negscale=None, batchnormalization=None, relu=None, prelu=None, fcmode=None, pool=0, operation=-1, scaling=None, data=None, name='max_pool2d0_output', caffename=None, input_addresses=[512], output_addresses=[0], data_movements=[], data_movement_costs=[], instructions=['5 XNScatter 0x200 0x0 2 2 1 0 1 1 0 1 0 1 # Output max_pool2d0_output'], fpga=True, replication=None, slice=0, padding_type='VALID', pipelined=None, parallel=[], scalepipeline=None, commutative_without_bias=None, deephi_quantizations=DeephiQuantization(inputs=[], outputs=[], weight=None, bias=None, immutable=False), quantz=None, collapse_future=[], collapse_past=[], memory_description='am_to_ddr', input_IO=[False], attrs={'full_paddings': [0, 0, 0, 0]})\n",
      "\n",
      "Done writing weights.\n",
      "SUCCESS True\n",
      "<class 'dict'>\n",
      "Add operation: max_pool2d0\n",
      "Max pool out: Tensor(shape=[1, 1, 2, 2], op.name=max_pool2d0)\n",
      "[1, 1, 2, 2]\n",
      "[{'op': 'null', 'name': 'x', 'inputs': []}, {'op': 'tvm_op', 'name': 'max_pool2d0', 'attrs': {'flatten_data': '0', 'func_name': 'fuse_max_pool2d', 'num_inputs': '1', 'num_outputs': '1'}, 'inputs': [[0, 0, 0]]}]\n",
      "Module(llvm, 21ddb70)\n",
      "{}\n",
      "\n",
      "XDNN SETUP FPGA EXECUTER\n",
      "\n",
      "\n",
      "XDNN CREATE GRAPH RUNTIME\n",
      "\n"
     ]
    }
   ],
   "source": [
    "platform = 'alveo-u200'\n",
    "\n",
    "config = {\n",
    "    'platform': platform,\n",
    "    'xclbin': \"../../../../MLsuite/overlaybins/\" + platform + \"/overlay_3.xclbin\",\n",
    "    'memory': 5,\n",
    "    'dsp': 56,\n",
    "    'netcfg': \"work/tvm_compiler.json\",\n",
    "    #'fromtensorflow': False,\n",
    "    'weights_name': \"weights\", \n",
    "    #datadir': \"work/weights_data\",\n",
    "    'quantizecfg': \"\", # Empty for now to test if quantization is needed in this simple example\n",
    "    'pngfile': \"graph.png\",\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "xdnn.xdnn_frontend.init(\n",
    "    platform=config['platform'],\n",
    "    xclbin=config['xclbin'],\n",
    "    memory=config['memory'],\n",
    "    dsp=config['dsp'],\n",
    "    netcfg=config['netcfg'],\n",
    "    weights_name=config['weights_name'],\n",
    "    input_shape=(1,1,4,4),\n",
    "    pngfile=config['pngfile'],\n",
    "    verbose=config['verbose']\n",
    ")\n",
    "\n",
    "if EXAMPLE == 1:\n",
    "    input_shape = (1,1,4,4)\n",
    "    input_type = 'float32'\n",
    "    output_shape = (1,1,2,2)\n",
    "    \n",
    "    data = np.reshape(np.array([[1,1,0,4],[5,1,0,8],\n",
    "                                [3,5,1,0],[1,9,3,4]]), input_shape)\n",
    "    x = sb.Variable(\"x\")\n",
    "    z = sb.max_pool2d(x, pool_size=[2,2], strides=[2,2])\n",
    "    graph = nnvm.graph.create(z)\n",
    "    print(graph.index.nodes)\n",
    "    \n",
    "    print(\"\\nNNVM COMPILER BUILD\\n\")\n",
    "    \n",
    "    params = {}\n",
    "    shape_dict = { 'x': input_shape }\n",
    "    dtype_dict = { 'x': input_type }\n",
    "    graph, lib, params = nnvm.compiler.build(\n",
    "                graph, target, shape_dict, dtype_dict,\n",
    "                params=params, target_host=target_host)\n",
    "    \n",
    "    print(graph.index.nodes)\n",
    "    print(lib)\n",
    "    print(params)\n",
    "\n",
    "    print(\"\\nXDNN SETUP FPGA EXECUTER\\n\")\n",
    "    # xdnn.xdnn_frontend.setup_fpga_executer()\n",
    "\n",
    "    print(\"\\nXDNN CREATE GRAPH RUNTIME\\n\")\n",
    "    #m = graph_runtime.create(graph, lib, ctx)\n",
    "    #m.set_input('x', tvm.nd.array(data.astype(input_type)))\n",
    "\n",
    "    #m.run()\n",
    "\n",
    "    #tvm_output = m.get_output(0, tvm.nd.empty(((1, 1, 2, 2)), 'float32'))\n",
    "\n",
    "    #print(tvm_output)\n",
    "    \n",
    "elif EXAMPLE == 2:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xfdnn.rt.xdnn as xdnn_lib\n",
    "\n",
    "os.environ['XDNN_VERBOSE'] = \"1\"\n",
    "\n",
    "ret, handles = xdnn_lib.createHandle(\"../../../../MLsuite/overlaybins/alveo-u200/overlay_3.xclbin\")\n",
    "\n",
    "if ret:                                                         \n",
    "    print(\"ERROR: Unable to create handle to FPGA\")\n",
    "else:\n",
    "    print(\"INFO: Successfully created handle to FPGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
